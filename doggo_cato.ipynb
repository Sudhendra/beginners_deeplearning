{"cells":[{"metadata":{"_uuid":"4325e265-3d80-4cf4-bd95-93e7c6d10750","_cell_guid":"07b53928-11e7-4053-afbc-30817e873371","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport cv2\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport random\nimport gc\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n# Any results you write to the current directory are saved as output.","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"746fdacf-2b34-4611-9a57-4a7279f1be52","_cell_guid":"495c5211-1619-4a40-88be-97f609cfca5c","trusted":true},"cell_type":"code","source":"train_dir = '../input/dogs-vs-cats-redux-kernels-edition/train'\ntest_dir = '../input/dogs-vs-cats-redux-kernels-edition/test'\n\ntrain_dogs = ['../input/dogs-vs-cats-redux-kernels-edition/train/{}'.format(i) for i in os.listdir(train_dir) if 'dog' in i] # get dog images\ntrain_cats = ['../input/dogs-vs-cats-redux-kernels-edition/train/{}'.format(i) for i in os.listdir(train_dir) if 'cat' in i] # get cat images\n\ntest_imgs = ['../input/dogs-vs-cats-redux-kernels-edition/test/{}'.format(i) for i in os.listdir(test_dir)] # get test images\n\ntrain_imgs = train_dogs[:2000] + train_cats[:2000] #slicing the dataset and using 2000 imges from each class\n\nrandom.shuffle(train_imgs) # shuffle the images randomly\n\n#delete the extra stuff to clean up the memory\ndel train_dogs\ndel train_cats\n# collect garbage to save memory\ngc.collect()","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"255dfd7f-b489-4d44-b439-572448e5657d","_cell_guid":"0270f7f8-404e-4b16-81ac-de7ff924f7f7","trusted":true},"cell_type":"code","source":"import matplotlib.image as mpimg\n\nfor ima in train_imgs[0:3]:\n    img = mpimg.imread(ima)\n    imgplot = plt.imshow(img)\n    plt.show()","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"1fbd2929-7440-44fb-b9aa-8b7420d513ee","_cell_guid":"2ed9f04d-d8ae-41de-8a6a-be0d5045aa83","trusted":true},"cell_type":"code","source":"# Lets declare image dimensions and reshape the images\n# 3 channles for R G B\nnrows = 150\nncols = 150\nchannels = 3\n\n# declare a function to read and process our images to a suitable format\n\ndef read_and_process_image(list_of_images):\n    X = [] #images\n    y = []#labels\n    \n    for image in list_of_images:\n        #print(image)\n        X.append(cv2.resize(cv2.imread(image, cv2.IMREAD_COLOR), (nrows, ncols), interpolation=cv2.INTER_CUBIC))\n        if 'dog.' in image:\n            y.append(1)\n        elif 'cat.' in image:\n            y.append(0)\n        \n        \n    return X,y","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"ac6fcc3e-acfb-4f6a-8960-44779895b8f2","_cell_guid":"8e1fd18f-370e-4ec3-a34f-8f908679aa27","trusted":true},"cell_type":"code","source":"# Processing pur images\n\nX,y = read_and_process_image(train_imgs)","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"fb39040c-d843-4479-bcb7-57e5e2f71461","_cell_guid":"4843bb1e-e1a3-4ad8-a2b0-ebaedf4fdbaa","trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,10))\ncolumns =5\nfor i in range (columns):\n    plt.subplot(5 / columns+1, columns, i+1)\n    plt.imshow(X[i])","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"a6b7bc15-cf5f-47b9-a89f-b807489f388b","_cell_guid":"e009ed6d-a1ae-4de8-b0d1-194ba22053a9","trusted":true},"cell_type":"code","source":"# Just to check if we really have 0's and 1's labelled properly\nimport seaborn as sns\ndel train_imgs\ngc.collect()\n\n# convert list to numpy array\nX = np.array(X)\ny = np.array(y)\n\nsns.countplot(y)\nplt.title('Labels for cats and dogs')","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"24549e16-c6a5-4ad3-b6e7-11cba0adf3c1","_cell_guid":"3ae0e253-3a6f-4847-8d94-029490c11587","trusted":true},"cell_type":"code","source":"print('Shape of train images is ',X.shape )\nprint('Shape of labels is ',y.shape)","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"4e5223d5-82ee-44eb-bbdf-0bf92dd31008","_cell_guid":"853eb049-cf0f-4eda-b645-a452a2c2fa19","trusted":true},"cell_type":"code","source":"# Preparing train and dev sets using sklearn library\nfrom sklearn.model_selection import train_test_split\nX_train, X_dev, y_train, y_dev =  train_test_split(X, y, test_size=0.10, random_state=2)\n\nprint('Shape of train images is: ',X_train.shape)\nprint('Shape of dev train images is: ',X_dev.shape)\nprint('Shape of train labels is: ', y_train.shape)\nprint('Shape of dev labels is: ',y_dev.shape)","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"028c8118-0227-499b-9cc3-b0cf33eab299","_cell_guid":"709295c6-1ed3-4818-8077-4b6b4fbc8d1a","trusted":true},"cell_type":"code","source":"del X\ndel y\ngc.collect()\n\n# get the length of train and dev sets\nntrain = len(X_train)\nndev = len(X_dev)\n# we will use a batch size of 32\nbatch_size = 32","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"998e538e-b921-4852-b53a-20600495e820","_cell_guid":"780a40c2-2f4c-477c-8b54-5c75c34c9420","trusted":true},"cell_type":"code","source":"# We will be using ConvNets (CNN's) with Keras\nfrom keras import layers\nfrom keras import models\nfrom keras import optimizers\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.preprocessing.image import img_to_array, load_img","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"451cfb68-f8d3-40f6-9536-2ebf32f87130","_cell_guid":"f9e8c624-6f28-48c7-802b-b729dfcd44b9","trusted":true},"cell_type":"code","source":"# We will be using the nn architecture of vggnet - Sequetial model\n\nmodel = models.Sequential()\nmodel.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(150,150,3)))\nmodel.add(layers.MaxPooling2D((2,2)))\nmodel.add(layers.Conv2D(65, (3,3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2,2)))\nmodel.add(layers.Conv2D(128, (3,3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2,2)))\nmodel.add(layers.Conv2D(128, (3,3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2,2)))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dropout(0.25)) # Dropout for regularization\nmodel.add(layers.Dense(512, activation='relu')) \nmodel.add(layers.Dense(1, activation='sigmoid')) # Sigmoid at the end because, binary classification\nmodel.summary()","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"142563f2-9ef8-4d6d-9683-dafdd464c567","_cell_guid":"9c41a35c-6d50-40ab-b57c-8aa1fec5f5be","trusted":true},"cell_type":"code","source":"# We'll use RMS prop optimizer with a learning rate of 0.0001\n# We'll use binary_crossentropy loss function cuz its a binary classification\n# We'll use accuracy (acc) metric to evaluate the performance after training since it's a classification problem\n\nmodel.compile(loss='binary_crossentropy', optimizer=optimizers.RMSprop(lr=1e-4), metrics=['acc'])","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"7a808629-a6f4-48ec-9ef0-4751fcb04b4d","_cell_guid":"0731ce93-a0fd-4298-8d16-c14baf2c94a2","trusted":true},"cell_type":"code","source":"# we are going to create 2 ImageDataGenerators -> Train, dev # Converts IMG to RGB and floating points to tensors -> easy to feed to a NN\n# Augmeting train_dataset: this helps preventingg overfitting, since we are using a relatively small dataset ## Normalization ##\ntrain_datagen = ImageDataGenerator(rescale=1./255, #Scale the image b/w 0 and 1 --> norm\n                                   rotation_range=40,\n                                   width_shift_range=0.2,\n                                   height_shift_range=0.2,\n                                   shear_range=0.2,\n                                   zoom_range=0.2,\n                                   horizontal_flip=True,\n                                  )\ndev_datagen = ImageDataGenerator(rescale=1./255) # No data augmentation in dev set, only rescaling","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"5666be20-882b-4156-9882-78d0fed68be6","_cell_guid":"4e7db82f-9af0-424b-8bcc-6a0628a86d7f","trusted":true},"cell_type":"code","source":"# Create Image generators\ntrain_generator = train_datagen.flow(X_train, y_train, batch_size=batch_size)\ndev_generator = dev_datagen.flow(X_dev, y_dev, batch_size=batch_size)","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"6bb04b81-efa1-46cc-af8f-9b1d0c2ebcaa","_cell_guid":"5163f7c0-dde5-4f0f-aedd-6f40fa1aded8","trusted":true},"cell_type":"code","source":"# The Training\n# Lets train for epochs and 100 steps per epoch and we use .fit() for training\n\nhistory = model.fit_generator(train_generator,\n                             steps_per_epoch = ntrain // batch_size,\n                             epochs=100,\n                             validation_data = dev_generator,\n                             validation_steps = ndev // batch_size)","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"14fc0e13-26b2-4bac-a359-4e3ad139cf3a","_cell_guid":"df58f410-e926-4300-8e51-c01e7b520917","trusted":true},"cell_type":"code","source":"#Save the model to reuse it later\nmodel.save_weights('model_weights.h5')\nmodel.save('model_keras.h5')","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"f4971f3a-b0b9-4a0a-91bb-4f1c617993a6","_cell_guid":"73b82578-8791-4f9a-8007-2f9facbba5dc","trusted":true},"cell_type":"code","source":"#lets plot graphs to get insights into accuracy and loss\n#get details from history object\n\nacc = history.history['acc']\ndev_acc = history.history['val_acc']\nloss = history.history['loss']\ndev_loss = history.history['val_loss']\n\nepochs = range(1, len(acc)+1)\n\n#train and dev accuaracy\nplt.plot(epochs, acc, 'b', label='Training accuracy')\nplt.plot(epochs, dev_acc, 'r', label='Dev accuracy')\nplt.title('Training and Dev accuracy')\nplt.legend()\nplt.figure()\n\n#train and dev loss\nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, dev_loss, 'r', label='Dev loss')\nplt.title('Training and Dev loss')\nplt.legend()\n\nplt.show()","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"a7fed408-a80c-4cb0-a523-010f3770c279","_cell_guid":"0c2513f0-da89-41ef-932f-e6851330cae1","trusted":true},"cell_type":"code","source":"#Now lets predict first 10 images from test set\nX_test, y_test = read_and_process_image(test_imgs[70:80]) #y_test will be empty here cuz, test set has no label\nx = np.array(X_test)\n\ntest_datagen = ImageDataGenerator(rescale=1./255)","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"0cf3a936-c075-49b0-8fe6-75268324d99a","_cell_guid":"0aa274f2-8230-41a1-811c-168a08342329","trusted":true},"cell_type":"code","source":"# Iterate through the images in test set and make predictions\ni=0\ntext_labels=[]\nplt.figure(figsize=(30,20))\nfor batch in test_datagen.flow(x, batch_size=1):\n    pred = model.predict(batch)\n    if pred > 0.5:\n        text_labels.append('dog')\n    else:\n        text_labels.append('cat')\n    plt.subplot(5 / columns+1, columns, i+1)\n    plt.title('This is a '+text_labels[i])\n    imgplot = plt.imshow(batch[0])\n    i += 1\n    if i%10==0:\n        break\nplt.show()","execution_count":0,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}